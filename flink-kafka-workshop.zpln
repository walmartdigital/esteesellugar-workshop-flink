{
  "paragraphs": [
    {
      "text": "%md\n# Enriquecimiento de datos en tiempo real\n\nEn este workshop veremos como enriquecer datos de un stream en tiempo real, haciendo uso de Kafka como fuente de datos y una API externa que nos provee la información adicional que necesitamos.\n\n## Conceptos\n\n- **kafka:** Es un sistema de mensajería publicador/suscriptor también conocido como un registro de log distribuido, diseñado para almacenar mensajes de forma ordenada y que estos puedan ser leídos de forma determinista. Es un data store muy utilizado en la industria y es una base para el procesamiento de datos en streaming.\n- **Stream de datos:** una secuencia ilimitada de datos ordenados e inmutables.\n- **Data inmutable:** data que no puede ser modificada una vez creada.\n- **Data store:** un lugar genérico donde se almacenan datos de cualquier tipo.\n- **Flink:** Es un framework de procesamiento de datos en streaming que difiere principalmente de otros como KafkaStreams o Faust por ser agnostico a la fuente de datos, siendo Kafka una fuente o destino de datos más y no su fuente principal.",
      "user": "anonymous",
      "dateUpdated": "2021-04-16T13:34:12+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Enriquecimiento de datos en tiempo real</h1>\n<p>En este workshop veremos como enriquecer datos de un stream en tiempo real, haciendo uso de Kafka como fuente de datos y una API externa que nos provee la información adicional que necesitamos.</p>\n<h2>Conceptos</h2>\n<ul>\n<li><strong>kafka:</strong> Es un sistema de mensajería publicador/suscriptor también conocido como un registro de log distribuido, diseñado para almacenar mensajes de forma ordenada y que estos puedan ser leídos de forma determinista. Es un data store muy utilizado en la industria y es una base para el procesamiento de datos en streaming.</li>\n<li><strong>Stream de datos:</strong> una secuencia ilimitada de datos ordenados e inmutables.</li>\n<li><strong>Data inmutable:</strong> data que no puede ser modificada una vez creada.</li>\n<li><strong>Data store:</strong> un lugar genérico donde se almacenan datos de cualquier tipo.</li>\n<li><strong>Flink:</strong> Es un framework de procesamiento de datos en streaming que difiere principalmente de otros como KafkaStreams o Faust por ser agnostico a la fuente de datos, siendo Kafka una fuente o destino de datos más y no su fuente principal.</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1618579598916_1639420366",
      "id": "paragraph_1618494605137_215480015",
      "dateCreated": "2021-04-16T13:26:38+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:739",
      "dateFinished": "2021-04-16T13:34:07+0000",
      "dateStarted": "2021-04-16T13:34:07+0000"
    },
    {
      "text": "%md\n# Agenda\n\n- Introducción al caso de uso\n- Probar un flujo simple en flink, desde un arreglo de datos\n- Extender el flujo con una petición remota\n- Crear un stream de datos usando Kafka\n- Consultar los datos enriquecidos desde el stream de Kafka",
      "user": "anonymous",
      "dateUpdated": "2021-04-16T13:35:24+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1618579646757_1149671721",
      "id": "paragraph_1618579646757_1149671721",
      "dateCreated": "2021-04-16T13:27:26+0000",
      "dateStarted": "2021-04-16T13:34:47+0000",
      "status": "FINISHED",
      "$$hashKey": "object:740",
      "dateFinished": "2021-04-16T13:34:47+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Agenda</h1>\n<ul>\n<li>Introducción al caso de uso</li>\n<li>Probar un flujo simple en flink, desde un arreglo de datos</li>\n<li>Extender el flujo con una petición remota</li>\n<li>Crear un stream de datos usando Kafka</li>\n<li>Consultar los datos enriquecidos desde el stream de Kafka</li>\n</ul>\n\n</div>"
          }
        ]
      }
    },
    {
      "text": "%flink\n\nimport java.util.Properties\nimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer\nimport org.apache.flink.streaming.util.serialization.SimpleStringSchema\n\nval properties = new Properties()\nproperties.setProperty(\"bootstrap.servers\", \"localhost:9092\")\nproperties.setProperty(\"group.id\", \"test\")\nval stream = senv\n    .addSource(new FlinkKafkaConsumer[String](\"topic\", new SimpleStringSchema(), properties))",
      "user": "anonymous",
      "dateUpdated": "2021-04-16T13:26:38+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import java.util.Properties\nimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer\nimport org.apache.flink.streaming.util.serialization.SimpleStringSchema\n\u001b[1m\u001b[34mproperties\u001b[0m: \u001b[1m\u001b[32mjava.util.Properties\u001b[0m = {}\n\u001b[1m\u001b[34mres1\u001b[0m: \u001b[1m\u001b[32mObject\u001b[0m = null\n\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mObject\u001b[0m = null\n\u001b[33mwarning: \u001b[0mthere was one deprecation warning; re-run with -deprecation for details\n\u001b[1m\u001b[34mstream\u001b[0m: \u001b[1m\u001b[32morg.apache.flink.streaming.api.scala.DataStream[String]\u001b[0m = org.apache.flink.streaming.api.scala.DataStream@1517047f\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1618579598917_106806939",
      "id": "paragraph_1618494166040_205323397",
      "dateCreated": "2021-04-16T13:26:38+0000",
      "status": "READY",
      "$$hashKey": "object:741"
    },
    {
      "text": "%md\n",
      "user": "anonymous",
      "dateUpdated": "2021-04-16T13:26:38+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1618579598918_564009012",
      "id": "paragraph_1618495125350_1979215751",
      "dateCreated": "2021-04-16T13:26:38+0000",
      "status": "READY",
      "$$hashKey": "object:742"
    }
  ],
  "name": "Flink Kafka Workshop",
  "id": "2G57UU9XC",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Flink Kafka Workshop"
}